{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "import os\n",
    "import cv2\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 30250 images belonging to 2 classes.\n",
      "Found 6300 images belonging to 2 classes.\n",
      "Found 6300 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_dir = \"/Users/jarvis/pymycod/tensorflow_AI/planetary/satellite/train\"\n",
    "test_dir = \"/Users/jarvis/pymycod/tensorflow_AI/planetary/satellite/test\"\n",
    "val_dir = \"/Users/jarvis/pymycod/tensorflow_AI/planetary/satellite/valid\"\n",
    "\n",
    "train_dataset = ImageDataGenerator(rescale=1.0/255,\n",
    "                                  rotation_range=0.4,\n",
    "                                  height_shift_range=0.2, \n",
    "                                  zoom_range=0.2, \n",
    "                            )\n",
    "train_gen = train_dataset.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(256,256),\n",
    "    batch_size=128,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "test_dataset = ImageDataGenerator(rescale=1.0/255,\n",
    "                                  rotation_range=0.4,\n",
    "                                  height_shift_range=0.2, \n",
    "                                  zoom_range=0.2, \n",
    "                            )\n",
    "test_gen = test_dataset.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(256,256),\n",
    "    batch_size=128,\n",
    "    class_mode='binary'\n",
    ")\n",
    "val_dataset = ImageDataGenerator(rescale=1.0/255,\n",
    "                                  rotation_range=0.4,\n",
    "                                  height_shift_range=0.2, \n",
    "                                  zoom_range=0.2, \n",
    "                            )\n",
    "val_gen = val_dataset.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(256,256),\n",
    "    batch_size=128,\n",
    "    class_mode='binary'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "236"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steps_train = 30250//128\n",
    "steps_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'nowildfire': 0, 'wildfire': 1}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_gen.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([keras.layers.Conv2D(32,(3,3),activation='relu',input_shape=(256,256,3)),\n",
    "                               keras.layers.MaxPool2D(2,2),\n",
    "                               keras.layers.Conv2D(64,(3,3),activation='relu'),\n",
    "                               keras.layers.MaxPool2D(2,2),\n",
    "                               keras.layers.BatchNormalization(),\n",
    "                               keras.layers.Dropout(0.2),\n",
    "                               keras.layers.Conv2D(128,(3,3),activation='relu'),\n",
    "                               keras.layers.MaxPool2D(2,2),\n",
    "                               keras.layers.Dropout(0.2),\n",
    "                               keras.layers.Conv2D(128,(3,3),activation='relu'),\n",
    "                               keras.layers.MaxPool2D(2,2),\n",
    "                               keras.layers.BatchNormalization(),\n",
    "                               keras.layers.Flatten(),\n",
    "                               keras.layers.Dense(512,activation='relu'),\n",
    "                               keras.layers.Dense(64,activation='relu'),\n",
    "                               keras.layers.Dense(1,activation='sigmoid')\n",
    "                               ])\n",
    "\n",
    "\n",
    "model.compile(loss = 'binary_crossentropy',\n",
    "                optimizer = Adam(learning_rate=0.001),\n",
    "                metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_40 (Conv2D)          (None, 254, 254, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d_40 (MaxPoolin  (None, 127, 127, 32)     0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_41 (Conv2D)          (None, 125, 125, 64)      18496     \n",
      "                                                                 \n",
      " max_pooling2d_41 (MaxPoolin  (None, 62, 62, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 62, 62, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 62, 62, 64)        0         \n",
      "                                                                 \n",
      " conv2d_42 (Conv2D)          (None, 60, 60, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_42 (MaxPoolin  (None, 30, 30, 128)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 30, 30, 128)       0         \n",
      "                                                                 \n",
      " conv2d_43 (Conv2D)          (None, 28, 28, 128)       147584    \n",
      "                                                                 \n",
      " max_pooling2d_43 (MaxPoolin  (None, 14, 14, 128)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 14, 14, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " flatten_10 (Flatten)        (None, 25088)             0         \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 512)               12845568  \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 64)                32832     \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,120,065\n",
      "Trainable params: 13,119,681\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:ModelCheckpoint mode <built-in function max> is unknown, fallback to auto mode.\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "model_path = \"/Users/jarvis/pymycod/tensorflow_AI/trained_models/lr_model_satellite_wildfires.h5\"\n",
    "checkpoint1 = ModelCheckpoint(model_path,monitor=\"val_accuracy\",verbose=1,save_best_only=True,mode=max)\n",
    "callbacks=[checkpoint1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-21 12:30:04.244869: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/jarvis/pymycod/tensorflow_AI/planetary/satellite_wildfire.ipynb Cell 10\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/jarvis/pymycod/tensorflow_AI/planetary/satellite_wildfire.ipynb#W6sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(train_gen,epochs\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m,verbose\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m,batch_size\u001b[39m=\u001b[39;49m\u001b[39m128\u001b[39;49m,steps_per_epoch\u001b[39m=\u001b[39;49msteps_train,validation_data\u001b[39m=\u001b[39;49mtest_gen,callbacks\u001b[39m=\u001b[39;49mcallbacks)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/tensor/lib/python3.8/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/tensor/lib/python3.8/site-packages/keras/engine/training.py:1401\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1399\u001b[0m \u001b[39mwith\u001b[39;00m data_handler\u001b[39m.\u001b[39mcatch_stop_iteration():\n\u001b[1;32m   1400\u001b[0m   data_handler\u001b[39m.\u001b[39m_initial_step \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_load_initial_step_from_ckpt()  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m-> 1401\u001b[0m   \u001b[39mfor\u001b[39;00m step \u001b[39min\u001b[39;00m data_handler\u001b[39m.\u001b[39msteps():\n\u001b[1;32m   1402\u001b[0m     \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1403\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m   1404\u001b[0m         epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   1405\u001b[0m         step_num\u001b[39m=\u001b[39mstep,\n\u001b[1;32m   1406\u001b[0m         batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[1;32m   1407\u001b[0m         _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[1;32m   1408\u001b[0m       callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/tensor/lib/python3.8/site-packages/keras/engine/data_adapter.py:1248\u001b[0m, in \u001b[0;36mDataHandler.steps\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1246\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_insufficient_data:  \u001b[39m# Set by `catch_stop_iteration`.\u001b[39;00m\n\u001b[1;32m   1247\u001b[0m   \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m-> 1248\u001b[0m original_spe \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_steps_per_execution\u001b[39m.\u001b[39;49mnumpy()\u001b[39m.\u001b[39mitem()\n\u001b[1;32m   1249\u001b[0m can_run_full_execution \u001b[39m=\u001b[39m (\n\u001b[1;32m   1250\u001b[0m     original_spe \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39mor\u001b[39;00m\n\u001b[1;32m   1251\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inferred_steps \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m\n\u001b[1;32m   1252\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inferred_steps \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_current_step \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m\n\u001b[1;32m   1253\u001b[0m     original_spe)\n\u001b[1;32m   1255\u001b[0m \u001b[39mif\u001b[39;00m can_run_full_execution:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/tensor/lib/python3.8/site-packages/tensorflow/python/ops/resource_variable_ops.py:637\u001b[0m, in \u001b[0;36mBaseResourceVariable.numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    635\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mnumpy\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    636\u001b[0m   \u001b[39mif\u001b[39;00m context\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 637\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread_value()\u001b[39m.\u001b[39;49mnumpy()\n\u001b[1;32m    638\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(\n\u001b[1;32m    639\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mnumpy() is only available when eager execution is enabled.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/tensor/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:1159\u001b[0m, in \u001b[0;36m_EagerTensorBase.numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1136\u001b[0m \u001b[39m\"\"\"Copy of the contents of this Tensor into a NumPy array or scalar.\u001b[39;00m\n\u001b[1;32m   1137\u001b[0m \n\u001b[1;32m   1138\u001b[0m \u001b[39mUnlike NumPy arrays, Tensors are immutable, so this method has to copy\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1156\u001b[0m \u001b[39m    NumPy dtype.\u001b[39;00m\n\u001b[1;32m   1157\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1158\u001b[0m \u001b[39m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[39;00m\n\u001b[0;32m-> 1159\u001b[0m maybe_arr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_numpy()  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   1160\u001b[0m \u001b[39mreturn\u001b[39;00m maybe_arr\u001b[39m.\u001b[39mcopy() \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(maybe_arr, np\u001b[39m.\u001b[39mndarray) \u001b[39melse\u001b[39;00m maybe_arr\n",
      "File \u001b[0;32m/opt/anaconda3/envs/tensor/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:1125\u001b[0m, in \u001b[0;36m_EagerTensorBase._numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1123\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_numpy\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m   1124\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1125\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_numpy_internal()\n\u001b[1;32m   1126\u001b[0m   \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m     \u001b[39mraise\u001b[39;00m core\u001b[39m.\u001b[39m_status_to_exception(e) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(train_gen,epochs=100,verbose=2,batch_size=128,steps_per_epoch=steps_train,validation_data=test_gen,callbacks=callbacks)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
